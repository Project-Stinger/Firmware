#!/usr/bin/env python3
"""
Step 8: Export Model for C++ Deployment

Export Random Forest model to C++ header file compatible with RP2040.
"""

import sys
import numpy as np
import joblib
from sklearn.tree import _tree

# Add utils to path
sys.path.insert(0, '.')

# Configuration
MODELS_DIR = 'outputs/models'
OUTPUT_DIR = 'outputs/deployment'


def export_tree_to_cpp(tree, feature_names, tree_idx):
    """
    Export a single decision tree to C++ code.

    Args:
        tree: sklearn DecisionTreeClassifier
        feature_names: List of feature names
        tree_idx: Index of this tree

    Returns:
        C++ code string
    """
    tree_ = tree.tree_
    feature_name = tree_.feature
    threshold = tree_.threshold

    cpp_code = []
    cpp_code.append(f"// Tree {tree_idx}")
    cpp_code.append(f"inline float tree_{tree_idx}(const float* features) {{")

    def recurse(node, depth):
        indent = "    " * (depth + 1)

        if tree_.feature[node] != _tree.TREE_UNDEFINED:
            # Internal node
            feature_idx = tree_.feature[node]
            threshold_val = tree_.threshold[node]

            cpp_code.append(f"{indent}if (features[{feature_idx}] <= {threshold_val:.8f}f) {{")
            recurse(tree_.children_left[node], depth + 1)
            cpp_code.append(f"{indent}}} else {{")
            recurse(tree_.children_right[node], depth + 1)
            cpp_code.append(f"{indent}}}")
        else:
            # Leaf node
            # Return probability of class 1 (pre-fire)
            value = tree_.value[node]
            prob_class_1 = value[0][1] / value[0].sum()
            cpp_code.append(f"{indent}return {prob_class_1:.8f}f;")

    recurse(0, 0)
    cpp_code.append("}\n")

    return "\n".join(cpp_code)


def export_random_forest_to_cpp(model, feature_names, scaler, threshold, output_path):
    """
    Export Random Forest model to C++ header file.

    Args:
        model: Trained RandomForestClassifier
        feature_names: List of feature names
        scaler: StandardScaler used for normalization
        threshold: Optimal threshold for classification
        output_path: Path to save C++ header file
    """
    n_trees = len(model.estimators_)
    n_features = len(feature_names)

    cpp_code = []

    # Header
    cpp_code.append("/**")
    cpp_code.append(" * Auto-generated Random Forest Model")
    cpp_code.append(" * Pre-Fire Prediction for Nerf Gun Flywheel Control")
    cpp_code.append(" *")
    cpp_code.append(" * DO NOT EDIT MANUALLY - Generated by 8_export_for_deployment.py")
    cpp_code.append(" */")
    cpp_code.append("")
    cpp_code.append("#pragma once")
    cpp_code.append("")
    cpp_code.append("#include <cmath>")
    cpp_code.append("")

    # Model metadata
    cpp_code.append("// Model Metadata")
    cpp_code.append(f"#define RF_N_TREES {n_trees}")
    cpp_code.append(f"#define RF_N_FEATURES {n_features}")
    cpp_code.append(f"#define RF_THRESHOLD {threshold:.8f}f")
    cpp_code.append("")

    # Feature normalization parameters
    cpp_code.append("// Feature Normalization (StandardScaler)")
    cpp_code.append("namespace RF_Normalization {")

    # Mean values
    cpp_code.append(f"    const float FEATURE_MEAN[{n_features}] = {{")
    for i, mean_val in enumerate(scaler.mean_):
        cpp_code.append(f"        {mean_val:.8f}f,  // {feature_names[i]}")
    cpp_code.append("    };")
    cpp_code.append("")

    # Scale values (1/std)
    cpp_code.append(f"    const float FEATURE_SCALE[{n_features}] = {{")
    for i, scale_val in enumerate(scaler.scale_):
        cpp_code.append(f"        {1.0/scale_val:.8f}f,  // {feature_names[i]}")
    cpp_code.append("    };")

    cpp_code.append("}")
    cpp_code.append("")

    # Feature normalization function
    cpp_code.append("// Normalize features")
    cpp_code.append("inline void normalize_features(float* features) {")
    cpp_code.append(f"    for (int i = 0; i < {n_features}; i++) {{")
    cpp_code.append("        features[i] = (features[i] - RF_Normalization::FEATURE_MEAN[i]) * RF_Normalization::FEATURE_SCALE[i];")
    cpp_code.append("    }")
    cpp_code.append("}")
    cpp_code.append("")

    # Individual trees
    cpp_code.append("// Decision Trees")
    for i, tree in enumerate(model.estimators_):
        tree_code = export_tree_to_cpp(tree, feature_names, i)
        cpp_code.append(tree_code)

    # Main prediction function
    cpp_code.append("// Random Forest Prediction")
    cpp_code.append("inline bool predict_prefire(float* features) {")
    cpp_code.append("    // Normalize features")
    cpp_code.append("    normalize_features(features);")
    cpp_code.append("")
    cpp_code.append("    // Average predictions from all trees")
    cpp_code.append("    float sum = 0.0f;")

    for i in range(n_trees):
        cpp_code.append(f"    sum += tree_{i}(features);")

    cpp_code.append(f"    float avg_prob = sum / {n_trees}.0f;")
    cpp_code.append("")
    cpp_code.append("    // Apply threshold")
    cpp_code.append("    return avg_prob >= RF_THRESHOLD;")
    cpp_code.append("}")
    cpp_code.append("")

    # Probability prediction function
    cpp_code.append("// Get prediction probability")
    cpp_code.append("inline float predict_prefire_probability(float* features) {")
    cpp_code.append("    // Normalize features")
    cpp_code.append("    normalize_features(features);")
    cpp_code.append("")
    cpp_code.append("    // Average predictions from all trees")
    cpp_code.append("    float sum = 0.0f;")

    for i in range(n_trees):
        cpp_code.append(f"    sum += tree_{i}(features);")

    cpp_code.append(f"    return sum / {n_trees}.0f;")
    cpp_code.append("}")

    # Write to file
    with open(output_path, 'w') as f:
        f.write("\n".join(cpp_code))


def create_usage_example(output_path):
    """Create example usage code."""
    example = """/**
 * Example Usage of Random Forest Model
 *
 * This example shows how to use the exported model in your C++ code.
 */

#include "rf_model.h"

void example_usage() {
    // Assume you have extracted 42 features from IMU data
    float features[42];

    // ... fill features array with your feature extraction code ...
    // (same as in ml_predictor.cpp)

    // Method 1: Get binary prediction
    bool should_prefire = predict_prefire(features);

    if (should_prefire) {
        // Activate flywheel pre-spin
        Serial.println("Pre-fire detected!");
    }

    // Method 2: Get prediction probability
    float prefire_probability = predict_prefire_probability(features);

    if (prefire_probability >= 0.7f) {
        // High confidence pre-fire
        Serial.printf("Pre-fire probability: %.2f\\n", prefire_probability);
    }
}

/**
 * Integration with ml_predictor.cpp
 *
 * Replace the model.predict() call with:
 */

// In ml_predictor.cpp, around line 282:
// Before:
//   static Eloquent::ML::Port::EloquentML model;
//   int prediction = model.predict(features);

// After:
//   #include "rf_model.h"
//   bool prediction = predict_prefire(features);

/**
 * Memory Usage Notes:
 *
 * - The model is compiled directly into your code (no runtime allocation)
 * - Stack usage: ~168 bytes for feature normalization (42 features * 4 bytes)
 * - Code size: Check build output for actual flash usage
 *
 * Tips for optimization:
 * - The feature array is modified in-place during normalization
 * - Make a copy if you need the original features
 * - Consider using consecutive prediction filtering to reduce false positives
 */

/**
 * Consecutive Prediction Filtering Example
 */

#define MIN_CONSECUTIVE_PREDICTIONS 20

static int consecutive_count = 0;
static bool filtered_prediction = false;

void update_prediction_with_filter(float* features) {
    bool raw_prediction = predict_prefire(features);

    if (raw_prediction) {
        consecutive_count++;
        if (consecutive_count >= MIN_CONSECUTIVE_PREDICTIONS) {
            filtered_prediction = true;
        }
    } else {
        consecutive_count = 0;
        filtered_prediction = false;
    }

    // Use filtered_prediction for flywheel control
    if (filtered_prediction) {
        // Activate flywheels
    }
}
"""

    with open(output_path, 'w') as f:
        f.write(example)


def main():
    print("="*80)
    print("STEP 8: EXPORT MODEL FOR DEPLOYMENT")
    print("="*80)

    # Create output directory
    import os
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # Load Random Forest model
    print("\n[1] Loading Random Forest model...")
    try:
        rf_results = joblib.load(f'{MODELS_DIR}/random_forest/results.pkl')
        model = rf_results['model']
        optimal_threshold = rf_results['optimal_threshold']
        size_info = rf_results['size_info']

        print(f"   ✓ Model loaded successfully")
        print(f"   Trees: {size_info['n_trees']}")
        print(f"   Total nodes: {size_info['total_nodes']:,}")
        print(f"   Estimated size: {size_info['estimated_size_kb']:.2f} KB")
        print(f"   Optimal threshold: {optimal_threshold:.4f}")
    except Exception as e:
        print(f"   ✗ Failed to load Random Forest model: {e}")
        print("\n   Please run 5_train_random_forest.py first!")
        return

    # Load feature metadata
    print("\n[2] Loading feature metadata...")
    feature_names = joblib.load('outputs/features/feature_names.pkl')
    scaler = joblib.load('outputs/features/scaler.pkl')

    print(f"   ✓ Loaded {len(feature_names)} features")
    print(f"   ✓ Loaded scaler")

    # Export to C++
    print("\n[3] Exporting model to C++ header file...")
    output_path = f'{OUTPUT_DIR}/rf_model.h'

    export_random_forest_to_cpp(
        model=model,
        feature_names=feature_names,
        scaler=scaler,
        threshold=optimal_threshold,
        output_path=output_path
    )

    print(f"   ✓ Exported to: {output_path}")

    # Calculate actual file size
    file_size_kb = os.path.getsize(output_path) / 1024
    print(f"   Header file size: {file_size_kb:.2f} KB")

    # Create usage example
    print("\n[4] Creating usage example...")
    example_path = f'{OUTPUT_DIR}/usage_example.cpp'
    create_usage_example(example_path)
    print(f"   ✓ Created: {example_path}")

    # Create README
    print("\n[5] Creating deployment README...")
    readme = f"""# Random Forest Model Deployment

## Model Information

- **Model Type**: Random Forest Classifier
- **Number of Trees**: {size_info['n_trees']}
- **Total Nodes**: {size_info['total_nodes']:,}
- **Total Leaves**: {size_info['total_leaves']:,}
- **Estimated Memory**: {size_info['estimated_size_kb']:.2f} KB
- **Header File Size**: {file_size_kb:.2f} KB
- **Optimal Threshold**: {optimal_threshold:.4f}

## Performance Metrics (Test Set)

- **Accuracy**: {rf_results['test_metrics_optimal']['accuracy']:.4f}
- **Precision**: {rf_results['test_metrics_optimal']['precision']:.4f}
- **Recall**: {rf_results['test_metrics_optimal']['recall']:.4f}
- **F1-Score**: {rf_results['test_metrics_optimal']['f1']:.4f}
- **ROC-AUC**: {rf_results['test_metrics_optimal']['roc_auc']:.4f}
- **False Positives/Second**: {rf_results['test_metrics_optimal']['fp_per_second']:.2f}

## Files

1. **rf_model.h** - Main model header file
   - Include this in your C++ project
   - Contains all tree structures and prediction functions
   - Self-contained (no external dependencies except <cmath>)

2. **usage_example.cpp** - Integration example
   - Shows how to use the model
   - Integration with ml_predictor.cpp
   - Consecutive prediction filtering example

## Integration Steps

1. Copy `rf_model.h` to your firmware's `src/` directory

2. In `ml_predictor.cpp`, replace the model prediction:
   ```cpp
   #include "rf_model.h"

   // In predict() function:
   bool prediction = predict_prefire(features);
   ```

3. Test in simulation or on hardware

4. Adjust threshold if needed:
   - Edit `RF_THRESHOLD` in `rf_model.h`
   - Higher = fewer false positives, lower recall
   - Lower = more catches, more false positives

## Memory Considerations

- **RP2040 has 264KB RAM** - this model should fit comfortably
- Model is compiled into flash (not RAM)
- Runtime stack usage: ~200 bytes
- No dynamic memory allocation

## Optimization Tips

1. **Consecutive Prediction Filtering**:
   - Require 10-20 consecutive positive predictions
   - Significantly reduces false positives
   - See usage_example.cpp for implementation

2. **Threshold Tuning**:
   - Start with optimal threshold: {optimal_threshold:.4f}
   - Increase for fewer false positives
   - Decrease for better trigger detection

3. **Feature Extraction**:
   - Ensure your feature extraction matches training
   - Window size: 50 samples
   - Same feature order (see feature_names.pkl)

## Testing Checklist

- [ ] Compile and verify no errors
- [ ] Test with known pre-fire patterns
- [ ] Measure false positive rate
- [ ] Verify flywheel response time
- [ ] Test with different users/grip styles
- [ ] Monitor performance over time
- [ ] Collect more data if needed

## Troubleshooting

**High false positive rate**:
- Increase threshold or consecutive count
- Check feature extraction implementation
- Collect more diverse training data

**Low recall (missing trigger pulls)**:
- Decrease threshold
- Verify IMU sampling rate (1600 Hz)
- Check prediction window timing (100-400ms)

**Compilation errors**:
- Ensure C++11 or later
- Check include paths
- Verify <cmath> is available

## Next Steps

After deployment:
1. Collect real-world performance data
2. Compare with original training metrics
3. Iterate on model if needed (retrain with new data)
4. Consider online learning/adaptation

---
Generated by MLmodel/8_export_for_deployment.py
"""

    with open(f'{OUTPUT_DIR}/README.md', 'w') as f:
        f.write(readme)

    print(f"   ✓ Created: {OUTPUT_DIR}/README.md")

    # Test the exported model
    print("\n[6] Testing exported model...")
    print("   Loading C++ header and verifying...")

    # Just verify the file can be read
    with open(output_path, 'r') as f:
        cpp_code = f.read()

    # Count lines and basic stats
    n_lines = cpp_code.count('\n')
    n_trees_in_code = cpp_code.count('inline float tree_')

    print(f"   ✓ Header file: {n_lines} lines")
    print(f"   ✓ Found {n_trees_in_code} tree functions")
    print(f"   ✓ Model export successful!")

    # Final summary
    print("\n" + "="*80)
    print("DEPLOYMENT EXPORT COMPLETE")
    print("="*80)

    print(f"\nExported files:")
    print(f"  ✓ {output_path}")
    print(f"  ✓ {example_path}")
    print(f"  ✓ {OUTPUT_DIR}/README.md")

    print(f"\nModel Summary:")
    print(f"  - Type: Random Forest with {size_info['n_trees']} trees")
    print(f"  - Memory: ~{size_info['estimated_size_kb']:.1f} KB")
    print(f"  - Performance: {rf_results['test_metrics_optimal']['f1']:.3f} F1-score")
    print(f"  - FP Rate: {rf_results['test_metrics_optimal']['fp_per_second']:.2f} FP/s")

    print(f"\nDeployment Ready:")
    print(f"  1. Copy {output_path} to your firmware src/ directory")
    print(f"  2. Include in ml_predictor.cpp")
    print(f"  3. Replace model.predict() with predict_prefire()")
    print(f"  4. Test and iterate!")

    print(f"\nSee {OUTPUT_DIR}/README.md for detailed integration instructions.")

    print("\n" + "="*80)
    print("ML PIPELINE COMPLETE!")
    print("="*80)


if __name__ == '__main__':
    main()
